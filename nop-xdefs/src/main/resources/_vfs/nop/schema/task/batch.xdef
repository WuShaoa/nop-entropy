<!--
@concurrency 同时启动多少个线程去并行处理
@retryOneByOne 重试的时候是否逐个重试，还是一整批重试
@singleMode表示批量读取数据，然后逐条处理、消费，而不是批量消费。
@rateLimit 每秒最多处理多少条记录
@jitterRatio 多线程执行时，如果每个线程处理的batchSize都相同，则可能导致同时读取数据库和同时写数据库，产生资源征用。 通过设置一个随机比例，将每个线程处理的batchSize动态调整为originalBatchSize * (1
                   + jitterRatio * random)， 使得每个线程的每个批次的负载随机化，从而破坏潜在的同步效应。
-->
<batch batchSize="!int" concurrency="!int=1" retryOneByOne="boolean=false"
       singleMode="boolean=false" singleSession="boolean"
       transactionScope="enum:io.nop.batch.core.BatchTransactionScope"
       rateLimit="double" jitterRatio="double"
       executor="string" xdef:name="BatchTaskModel" xdef:bean-package="io.nop.batch.dsl.model"
       x:schema="/nop/schema/xdef.xdef" xmlns:x="/nop/schema/xdsl.xdef"
       xmlns:xdef="/nop/schema/xdef.xdef"
>
    <retryPolicy maxRetryCount="int" retryDelay="int" maxRetryDelay="int" xdef:name="BatchRetryPolicyModel"
                 exponentialDelay="boolean=true" jitterRatio="double=0.3">
        <exceptionFilter xdef:value="xpl-fn:(err)=>boolean"/>
    </retryPolicy>

    <skipPolicy maxSkipCount="long" xdef:name="BatchSkipPolicyModel">
        <exceptionFilter xdef:value="xpl-fn:(err)=>boolean"/>
    </skipPolicy>

    <inputSorter xdef:ref="/nop/schema/query/order-by.xdef"/>

    <xdef:define xdef:name="BatchListenersModel">
        <onTaskBegin xdef:value="xpl-fn:(ctx)=>void"/>
        <onTaskEnd xdef:value="xpl-fn:(err,ctx)=>void"/>

        <onChunkBegin xdef:value="xpl-fn:(ctx)=>void"/>
        <onChunkEnd xdef:value="xpl-fn:(err,ctx)=>void"/>

        <onLoadBegin xdef:value="xpl-fn:(batchSize,ctx)=>void"/>
        <onLoadEnd xdef:value="xpl-fn:(err,batchSize,ctx)=>void"/>

        <onConsumeBegin xdef:value="xpl-fn:(items,ctx)=>void"/>
        <onConsumeEnd xdef:value="xpl-fn:(err,items,ctx)=>void"/>
    </xdef:define>

    <reader bean="bean-name" xdef:name="BatchReaderModel" aggregator="bean-name"
            xdef:ref="BatchListenersModel" xdef:mandatory="true">
        <file-reader pathExpr="!expr" xdef:name="BatchFileReaderModel" encoding="string"
                     resourceLoader="bean-name" resourceIO="bean-name" maxCount="long">
            <headers xdef:value="csv-set"/>
        </file-reader>

        <orm-reader xdef:name="BatchOrmReaderModel" batchLoadProps="csv-list" entityName="class-name">
            <eql xdef:value="xpl-sql"/>
            <query xdef:ref="../query/query.xdef"/>
        </orm-reader>

        <jdbc-reader querySpace="string" sqlName="string" xdef:name="BatchJdbcReaderModel">
            <sql xdef:value="xpl-sql"/>
            <query xdef:ref="../query/query.xdef"/>
        </jdbc-reader>

        <source xdef:value="xpl-fn:(batchSize,ctx)=>List"/>
    </reader>

    <processor bean="bean-name" id="var-name" order="!int=0"
               xdef:unique-attr="id" xdef:name="BatchProcessorModel" xdef:ref="BatchListenersModel">
        <filter xdef:value="xpl-predicate"/>
        <source xdef:value="xpl-fn:(item,consumer,ctx)=>void"/>
    </processor>

    <chunk-processor bean="bean-name" xdef:name="BatchChunkProcessorModel" xdef:ref="BatchListenersModel">
        <source xdef:value="xpl-fn:(ctx)=>void"/>
    </chunk-processor>

    <tagger bean="bean-name" xdef:name="BatchTaggerModel">
        <source xdef:value="xpl-fn:(item,ctx)=>Collection"/>
    </tagger>

    <writer bean="bean-name" id="var-name" order="!int=0" forTag="string"
            xdef:unique-attr="id" xdef:name="BatchWriterModel" xdef:ref="BatchListenersModel"
            aggregator="bean-name" metaProvider="bean-name">
        <file-writer pathExpr="!expr" xdef:name="BatchFileWriterModel" encoding="string"
                     resourceLoader="bean-name" resourceIO="bean-name">
            <headers xdef:value="csv-set"/>
        </file-writer>

        <source xdef:value="xpl-fn:(items,ctx)=>void"/>
    </writer>

</batch>